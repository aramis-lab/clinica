templates_dict = {
  "t1-linear": "MNI152NLin2009cSym",
  "t1-volume": "Ixi549Space"
}


def extract_roi(input_path, basedir, masks_location, input_pattern, roi_list, uncrop_output, template):
    """Extracts regions of interest defined by masks

    This function extracts regions of interest from the preprocessed nifti image.
    The regions are defined using binary masks that must be located in the CAPS
    at `masks/roi_based/t1_linear`.

    Args:
        input_path: path to the tensor version of the nifti MRI.
        basedir: path to the extracted files.
        roi_list: list of the names of the regions that will be extracted.
        uncrop_output: if True, the final region is not cropped.
        template: name of the template used for the preprocessing pipeline.

    Returns:
        file: multiple tensors saved on the disk, suffixes corresponds to
            indexes of the patches. Same location than input file.
    """
    import torch
    import nibabel as nib
    import os
    import numpy as np
    from os import path

    crop_desc = ""
    if not uncrop_output:
        crop_desc = "_desc-Crop"

    image_array = nib.load(input_path).get_fdata()
    image_tensor = torch.from_numpy(image_array).unsqueeze(0).float()

    input_tensor_filename = os.path.basename(input_path)
    txt_idx = input_tensor_filename.rfind("_")
    it_filename_prefix = input_tensor_filename[0:txt_idx]
    it_filename_suffix = input_tensor_filename[txt_idx:].split('.')[0]

    output_roi = []
    for index_roi, roi in enumerate(roi_list):
        roi_path = path.join(masks_location, "tpl-%s_%s_roi-%s_mask.nii.gz" % (template, input_pattern, roi))
        roi_mask = nib.load(roi_path).get_fdata()
        if len(roi_mask.shape) == 3:
            roi_mask = roi_mask[np.newaxis, :]

        extracted_roi = image_tensor * roi_mask
        if not uncrop_output:
            extracted_roi = extracted_roi[np.ix_(roi_mask.any((1, 2, 3)),
                                                 roi_mask.any((0, 2, 3)),
                                                 roi_mask.any((0, 1, 3)),
                                                 roi_mask.any((0, 1, 2)))]
        extracted_roi = extracted_roi.float()
        # save into .pt format
        output_roi.append(
            os.path.join(
                basedir,
                "%s_roi-%s%s%s.pt" % (it_filename_prefix, roi, crop_desc, it_filename_suffix)
            )
        )
        os.makedirs(output_path, exist_ok=True)
        torch.save(extracted_roi.clone(), output_roi[index_roi])

    return output_roi


def check_mask_list(masks_location, roi_list, input_pattern):
    from os import path
    import numpy as np
    import nibabel as nib

    for roi in enumerate(roi_list):
        roi_path = path.join(masks_location, "roi-%s_%s_mask.nii.gz" % (roi, input_pattern))
        if not path.exists(roi_path):
            raise ValueError('The ROI wanted do not correspond to a mask in the CAPS directory.'
                             'It should be written at the following path: %s' % roi_path)
        roi_mask = nib.load(roi_path).get_fdata()
        mask_values = set(np.unique(roi_mask))
        if mask_values != {0, 1}:
            raise ValueError('The ROI masks used should be binary (composed of 0 and 1 only).')


if __name__ == "__main__":
    import argparse
    from os import path
    import os

    from ...utils.inputs import clinica_file_reader

    parser = argparse.ArgumentParser(description="Temporary parser for the extraction of ROI tensors.")

    parser.add_argument("caps_directory", type=str, help="path to the CAPS directory.")
    parser.add_argument('-uui', '--use_uncropped_image',
                        help='''Use the uncropped image instead of the cropped image generated by t1-linear.''',
                        default=False, action="store_true")
    parser.add_argument("--roi_list", type=str, nargs="+", default=None,
                        help="List of regions to be extracted")
    parser.add_argument("--uncrop_output", action="store_true", default=False,
                        help="Disable cropping option so the output tensors have the same size than the whole image.")
    args = parser.parse_args()

    cropping = "desc-Crop_"
    if args.use_uncropped_image:
        cropping = ""

    preprocessing = "t1-linear"
    input_pattern = "%sres-1x1x1" % cropping

    # Load the corresponding masks
    masks_location = path.join(args.caps_directory, 'masks', 'roi_based', "tpl-%s" % templates_dict[preprocessing])

    if args.roi_list is None:
        args.roi_list = [mask.split("_")[-2].split("-")[1] for mask in os.listdir(masks_location)]
        if len(args.roi_list) == 0:
            raise ValueError('No ROI was specified, and no mask was found at %s' % masks_location)
    else:
        check_mask_list(masks_location, args.roi_list, input_pattern)

    for subject in os.listdir(path.join(args.caps_directory, "subjects")):
        subject_path = path.join(args.caps_directory, "subjects", subject)
        for session in os.listdir(subject_path):
            input_path = clinica_file_reader([subject], [session], args.caps_directory,
                                             {"needed_pipeline": preprocessing,
                                              "pattern": "*%s*.nii.gz" % input_pattern,
                                              "description": "cropped output of t1-linear"})[0]
            output_path = path.join(subject_path, session, "deeplearning_prepare_data", "roi_based", "t1_linear")
            extract_roi(input_path, output_path, masks_location, input_pattern,
                        roi_list=args.roi_list, uncrop_output=args.uncrop_output,
                        template=templates_dict[preprocessing])
